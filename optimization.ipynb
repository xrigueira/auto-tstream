{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer for time series modeling\n",
    "These are the inputs and outputs to the model.\n",
    "- Inputs: SWIT.\n",
    "- Output: Streamflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import utils\n",
    "import dataset as ds\n",
    "from models.autoformer import Autoformer\n",
    "from models.informer import Informer\n",
    "from models.fedformer import FEDformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train, test, validation and optimization steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define train step\n",
    "def train(dataloader, model, loss_function, optimizer, device, df_training, epoch):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    training_loss = [] # For plotting purposes\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        src, tgt, tgt_y, src_pe, tgt_pe = batch\n",
    "        src, tgt, tgt_y, src_pe, tgt_pe = src.float().to(device), tgt.float().to(device), tgt_y.float().to(device), src_pe.float().to(device), tgt_pe.float().to(device)\n",
    "        \n",
    "        # Zero out gradients for every batch\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Process decoder input\n",
    "        decoder_input = torch.zeros_like(tgt[:, -output_sequence_len:, :]).float()\n",
    "        decoder_input = torch.cat([tgt[:, :decoder_sequence_len, :], decoder_input], dim=1).float().to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred, attention_weights = model(src, decoder_input, src_pe, tgt_pe)\n",
    "        \n",
    "        f_dim = -1 if features == 'MS' else 0\n",
    "        pred = pred[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "        tgt_y = tgt_y[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "        \n",
    "        loss = loss_function(pred, tgt_y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Save results for plotting\n",
    "        training_loss.append(loss.item())\n",
    "        epoch_train_loss = np.mean(training_loss)\n",
    "        df_training.loc[epoch] = [epoch, epoch_train_loss]\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('Current batch', i)\n",
    "            loss, current = loss.item(), (i + 1) * len(src)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# Define test step\n",
    "def test(dataloader, model, loss_function, device, df_testing, epoch):\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    testing_loss = [] # For plotting purposes\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = batch\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = src.float().to(device), tgt.float().to(device), tgt_y.float().to(device), src_pe.float().to(device), tgt_pe.float().to(device)\n",
    "            \n",
    "            # Process decoder input\n",
    "            decoder_input = torch.zeros_like(tgt[:, -output_sequence_len:, :]).float()\n",
    "            decoder_input = torch.cat([tgt[:, :decoder_sequence_len, :], decoder_input], dim=1).float().to(device)\n",
    "            \n",
    "            # Compute prediction error\n",
    "            pred, attention_weights = model(src, decoder_input, src_pe, tgt_pe)\n",
    "            \n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            pred = pred[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "            tgt_y = tgt_y[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "        \n",
    "            loss = loss_function(pred, tgt_y)\n",
    "            \n",
    "            # Save results for plotting\n",
    "            testing_loss.append(loss.item())\n",
    "            epoch_test_loss = np.mean(testing_loss)\n",
    "            df_testing.loc[epoch] = [epoch, epoch_test_loss]\n",
    "    \n",
    "    loss /= num_batches\n",
    "    # print(f\"Avg test loss: {loss:>8f}\")\n",
    "\n",
    "# Define validation step\n",
    "def validation(dataloader, model):\n",
    "    \n",
    "    # Define lists to store the predictions and ground truth\n",
    "    y_hats = []\n",
    "    tgt_ys = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = batch\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = src.float().to(device), tgt.float().to(device), tgt_y.float().to(device), src_pe.float().to(device), tgt_pe.float().to(device)\n",
    "            \n",
    "            # Process decoder input\n",
    "            decoder_input = torch.zeros_like(tgt[:, -output_sequence_len:, :]).float()\n",
    "            decoder_input = torch.cat([tgt[:, :decoder_sequence_len, :], decoder_input], dim=1).float().to(device)\n",
    "            \n",
    "            # Compute prediction error\n",
    "            pred, attention_weights = model(src, decoder_input, src_pe, tgt_pe)\n",
    "            \n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            pred = pred[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "            tgt_y = tgt_y[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "            \n",
    "            y_hat = pred.detach().cpu().numpy()\n",
    "            tgt_y = tgt_y.detach().cpu().numpy()\n",
    "            \n",
    "            y_hats.append(y_hat)\n",
    "            tgt_ys.append(tgt_y)\n",
    "    \n",
    "    y_hats = np.concatenate(y_hats, axis=0)\n",
    "    tgt_ys = np.concatenate(tgt_ys, axis=0)\n",
    "    print('Validation shape:', y_hats.shape, tgt_ys.shape)\n",
    "    y_hats = y_hats.reshape(-1, y_hats.shape[-2], y_hats.shape[-1])\n",
    "    tgt_ys = tgt_ys.reshape(-1, tgt_ys.shape[-2], tgt_ys.shape[-1])\n",
    "    print('Validation shape:', y_hats.shape, tgt_ys.shape)\n",
    "    \n",
    "    # Get metrics\n",
    "    mae, mse, rmse, mape, mspe = utils.metric(y_hats, tgt_ys)\n",
    "    print('MSE: {}\\nMAE: {}'.format(mse, mae))\n",
    "    \n",
    "    return y_hats.squeeze(), tgt_ys.squeeze()\n",
    "\n",
    "# Define function to train, test and evaluate the model\n",
    "def train_test_val(lr, d_model, n_heads, n_encoder_layers, n_decoder_layers, encoder_features_fc_layer, decoder_features_fc_layer):\n",
    "\n",
    "    # Build model\n",
    "    if model_selection == 'autoformer':\n",
    "        model = Autoformer(encoder_sequence_len=encoder_sequence_len, decoder_sequence_len=decoder_sequence_len, output_sequence_len=output_sequence_len,\n",
    "                    encoder_input_size=encoder_input_size, decoder_input_size=decoder_input_size, decoder_output_size=decoder_output_size, \n",
    "                    encoder_features_fc_layer=encoder_features_fc_layer, decoder_features_fc_layer=decoder_features_fc_layer, n_encoder_layers=n_encoder_layers,\n",
    "                    n_decoder_layers=n_decoder_layers, activation=activation, embed=embed, d_model=d_model, n_heads=n_heads, attention_factor=attention_factor,\n",
    "                    frequency=frequency, dropout=dropout, output_attention=output_attention, moving_average=moving_average).float()\n",
    "    elif model_selection == 'informer':\n",
    "        model = Informer(output_sequence_len=output_sequence_len, encoder_input_size=encoder_input_size, decoder_input_size=decoder_input_size, \n",
    "                        decoder_output_size=decoder_output_size, encoder_features_fc_layer=encoder_features_fc_layer, decoder_features_fc_layer=decoder_features_fc_layer, \n",
    "                        n_encoder_layers=n_encoder_layers, n_decoder_layers=n_decoder_layers, activation=activation, embed=embed, d_model=d_model, n_heads=n_heads, \n",
    "                        attention_factor=attention_factor, frequency=frequency, dropout=dropout, distill=distill, output_attention=output_attention).float()\n",
    "    elif model_selection == 'fedformer':\n",
    "        model = FEDformer(encoder_sequence_len=encoder_sequence_len, decoder_sequence_len=decoder_sequence_len, output_sequence_len=output_sequence_len,\n",
    "                        encoder_input_size=encoder_input_size, decoder_input_size=decoder_input_size , decoder_output_size=decoder_output_size, \n",
    "                        encoder_features_fc_layer=encoder_features_fc_layer, decoder_features_fc_layer=decoder_features_fc_layer, n_encoder_layers=n_encoder_layers, \n",
    "                        n_decoder_layers=n_decoder_layers, activation=activation, embed=embed, d_model=d_model, n_heads=n_heads, frequency=frequency, \n",
    "                        dropout=dropout, output_attention=output_attention, moving_average=moving_average, version=version, mode_select=model_selection, \n",
    "                        modes=modes, L=L, base=base, cross_activation=cross_activation, wavelet=wavelet).float()\n",
    "    else:\n",
    "        raise ValueError('Model not implemented')\n",
    "\n",
    "    # Send model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Update model in the training process and test it\n",
    "    epochs = 5 # 250\n",
    "    start_time = time.time()\n",
    "    df_training = pd.DataFrame(columns=('epoch', 'loss_train'))\n",
    "    df_testing = pd.DataFrame(columns=('epoch', 'loss_test'))\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(training_data, model, loss_function, optimizer, device, df_training, epoch=t)\n",
    "        test(testing_data, model, loss_function, device, df_testing, epoch=t)\n",
    "    print(\"Done! ---Execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Inference\n",
    "    y_hats, tgt_ys = validation(validation_data, model)\n",
    "\n",
    "    nse = utils.nash_sutcliffe_efficiency(tgt_ys, y_hats)\n",
    "\n",
    "    return nse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hypeparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # Define seed\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # Hyperparams\n",
    "    test_size = 0.2\n",
    "    val_size = 0.1\n",
    "    batch_size = 128\n",
    "    src_variables = ['X']\n",
    "    tgt_variables = ['y']\n",
    "    input_variables = src_variables + tgt_variables\n",
    "    timestamp_col_name = \"time\"\n",
    "    model_selection = 'autoformer' # 'autoformer', 'informer', 'fedformer'\n",
    "\n",
    "    encoder_sequence_len = 365 # length of input given to encoder\n",
    "    decoder_sequence_len = 1 # length of input given to decoder\n",
    "    output_sequence_len = 2 # target sequence length (the informer does not work with 1 step ahead)\n",
    "    encoder_input_size = 1\n",
    "    decoder_input_size = 1\n",
    "    decoder_output_size = 1 \n",
    "    # encoder_features_fc_layer = 32\n",
    "    # decoder_features_fc_layer = 32\n",
    "    # n_encoder_layers = 2\n",
    "    # n_decoder_layers = 1\n",
    "    activation = 'gelu'\n",
    "    embed = 'time_frequency'\n",
    "    # d_model = 16\n",
    "    # n_heads = 2\n",
    "    attention_factor = 1\n",
    "    frequency = 'd'\n",
    "    dropout = 0.05\n",
    "    distill = True # For the Informer: whether to use distilling in encoder, using this argument means not using distilling\n",
    "    output_attention = True # Keep True for now\n",
    "    moving_average = 25\n",
    "    window_size = encoder_sequence_len + output_sequence_len\n",
    "    step_size = 1\n",
    "\n",
    "    # FEDformer specific hyperparams\n",
    "    L = 1\n",
    "    ab = 0\n",
    "    modes = 32\n",
    "    mode_select = 'random'\n",
    "    version = 'Wavelets' # 'Wavelets' or 'Fourier'\n",
    "    base = 'legendre'\n",
    "    cross_activation = 'tanh'\n",
    "    wavelet = 0\n",
    "\n",
    "    num_workers = 8\n",
    "    features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Get device\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Read the data\n",
    "    data = utils.read_data(timestamp_col_name=timestamp_col_name)\n",
    "    data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "    # Extract train, test, and validation temporal data for position encoding\n",
    "    training_data_pe = data[:-(round(len(data)*(test_size+val_size)))].iloc[:, :1]\n",
    "    testing_data_pe = data.iloc[:, :1][(round(len(data)*(1-test_size-val_size))):(round(len(data)*(1-val_size)))]\n",
    "    validation_data_pe = data.iloc[:, :1][(round(len(data)*(1-val_size))):]\n",
    "\n",
    "    # Adapt to prediction task\n",
    "    if features == 'M' or features == 'MS':\n",
    "        cols_data = data.columns[1:]\n",
    "        data = data[cols_data]\n",
    "    elif features == 'S':\n",
    "        data = data[[tgt_variables[0]]]\n",
    "\n",
    "    # Extract train, test and validaiton data\n",
    "    training_data = data[:-(round(len(data)*(test_size+val_size)))]\n",
    "    testing_data = data[(round(len(data)*(1-test_size-val_size))):(round(len(data)*(1-val_size)))]\n",
    "    validation_data = data[(round(len(data)*(1-val_size))):]\n",
    "\n",
    "    # Make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chuncks\n",
    "    training_indices = utils.get_indices(data=training_data, window_size=window_size, step_size=step_size)\n",
    "    testing_indices = utils.get_indices(data=testing_data, window_size=window_size, step_size=step_size)\n",
    "    validation_indices = utils.get_indices(data=validation_data, window_size=window_size, step_size=step_size)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Fit scaler on the training set\n",
    "    scaler.fit(training_data.values)\n",
    "\n",
    "    training_data = scaler.transform(training_data.values)\n",
    "    testing_data = scaler.transform(testing_data.values)\n",
    "    validation_data = scaler.transform(validation_data.values)\n",
    "\n",
    "    # Extract positional encoding data\n",
    "    training_data_pe = utils.positional_encoder(training_data_pe, time_encoding='time_frequency', frequency='d')\n",
    "    testing_data_pe = utils.positional_encoder(testing_data_pe, time_encoding='time_frequency', frequency='d')\n",
    "    validation_data_pe = utils.positional_encoder(validation_data_pe, time_encoding='time_frequency', frequency='d')\n",
    "\n",
    "    # Make instance of the custom dataset class\n",
    "    training_data = ds.AutoTransformerDataset(data=torch.tensor(training_data), data_pe=torch.tensor(training_data_pe),\n",
    "                                            indices=training_indices, encoder_sequence_len=encoder_sequence_len, \n",
    "                                            decoder_sequence_len=decoder_sequence_len, tgt_sequence_len=output_sequence_len)\n",
    "    testing_data = ds.AutoTransformerDataset(data=torch.tensor(testing_data), data_pe=torch.tensor(testing_data_pe),\n",
    "                                            indices=testing_indices, encoder_sequence_len=encoder_sequence_len,\n",
    "                                            decoder_sequence_len=decoder_sequence_len, tgt_sequence_len=output_sequence_len)\n",
    "    validation_data = ds.AutoTransformerDataset(data=torch.tensor(validation_data), data_pe=torch.tensor(validation_data_pe),\n",
    "                                            indices=validation_indices, encoder_sequence_len=encoder_sequence_len,\n",
    "                                            decoder_sequence_len=decoder_sequence_len, tgt_sequence_len=output_sequence_len)\n",
    "\n",
    "    # Set up the dataloaders\n",
    "    training_data = DataLoader(training_data, batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "    testing_data = DataLoader(testing_data, batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "    validation_data = DataLoader(validation_data, batch_size=1, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and perform optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Set up experiment hyperparams\n",
    "    experiment_hyperparams = {\n",
    "        'lr': [1e-5, 0.001],\n",
    "        'd_model': [32, 64, 128, 256, 512],\n",
    "        'n_heads': [2, 4, 8],\n",
    "        'n_encoder_layers': [1, 2, 4],\n",
    "        'n_decoder_layers': [1, 2, 4],\n",
    "        'encoder_features_fc_layer': [32, 64, 128],\n",
    "        'decoder_features_fc_layer': [32, 64, 128],\n",
    "    }\n",
    "\n",
    "    # Run optimization loop\n",
    "    counter = 0\n",
    "    optimization_df = pd.DataFrame(columns=('lr', 'd_model', 'n_heads', 'n_encoder_layers', 'n_decoder_layers', 'encoder_features_fc_layer', 'decoder_features_fc_layer', 'nse'))\n",
    "    for lr in experiment_hyperparams['lr']:\n",
    "        for d_model in experiment_hyperparams['d_model']:\n",
    "            for n_heads in experiment_hyperparams['n_heads']:\n",
    "                for n_encoder_layers in experiment_hyperparams['n_encoder_layers']:\n",
    "                    for n_decoder_layers in experiment_hyperparams['n_decoder_layers']:\n",
    "                        for encoder_features_fc_layer in experiment_hyperparams['encoder_features_fc_layer']:\n",
    "                            for decoder_features_fc_layer in experiment_hyperparams['decoder_features_fc_layer']:\n",
    "                                \n",
    "                                print(f'Iteration {counter}')\n",
    "                                nse = train_test_val(lr, d_model, n_heads, n_encoder_layers, n_decoder_layers, encoder_features_fc_layer, decoder_features_fc_layer)\n",
    "                                \n",
    "                                # Append parameters and nse to dataframe\n",
    "                                optimization_df.loc[counter] = [lr, d_model, n_heads, n_encoder_layers, n_decoder_layers, \n",
    "                                                    encoder_features_fc_layer, decoder_features_fc_layer, nse]\n",
    "                                \n",
    "                                # Update counter\n",
    "                                counter += 1\n",
    "                                \n",
    "    # Save dataframe to my Google Drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    optimization_df.to_csv('/content/drive/My Drive/optimization_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
