{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer for time series modeling\n",
    "These are the inputs and outputs to the model.\n",
    "- Inputs: SWIT.\n",
    "- Output: Streamflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import utils\n",
    "import dataset as ds\n",
    "from models.autoformer import Autoformer\n",
    "from models.informer import Informer\n",
    "from models.fedformer import FEDformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train, test, and validations steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define train step\n",
    "def train(dataloader, model, loss_function, optimizer, device, df_training, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    training_loss = [] # For plotting purposes\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        src, tgt, tgt_y, src_pe, tgt_pe = batch\n",
    "        src, tgt, tgt_y, src_pe, tgt_pe = src.float().to(device), tgt.float().to(device), tgt_y.float().to(device), src_pe.float().to(device), tgt_pe.float().to(device)\n",
    "        \n",
    "        # Zero out gradients for every batch\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # Process decoder input\n",
    "        decoder_input = torch.zeros_like(tgt[:, -output_sequence_len:, :]).float()\n",
    "        decoder_input = torch.cat([tgt[:, :decoder_sequence_len, :], decoder_input], dim=1).float().to(device)\n",
    "        \n",
    "        # Compute prediction error\n",
    "        pred, attention_weights = model(src, decoder_input, src_pe, tgt_pe)\n",
    "        \n",
    "        f_dim = -1 if features == 'MS' else 0\n",
    "        pred = pred[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "        tgt_y = tgt_y[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "        \n",
    "        loss = loss_function(pred, tgt_y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Save results for plotting\n",
    "        training_loss.append(loss.item())\n",
    "        epoch_train_loss = np.mean(training_loss)\n",
    "        df_training.loc[epoch] = [epoch, epoch_train_loss]\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print('Current batch', i)\n",
    "            loss, current = loss.item(), (i + 1) * len(src)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "# Define test step\n",
    "def test(dataloader, model, loss_function, device, df_testing, epoch):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    testing_loss = [] # For plotting purposes\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = batch\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = src.float().to(device), tgt.float().to(device), tgt_y.float().to(device), src_pe.float().to(device), tgt_pe.float().to(device)\n",
    "            \n",
    "            # Process decoder input\n",
    "            decoder_input = torch.zeros_like(tgt[:, -output_sequence_len:, :]).float()\n",
    "            decoder_input = torch.cat([tgt[:, :decoder_sequence_len, :], decoder_input], dim=1).float().to(device)\n",
    "            \n",
    "            # Compute prediction error\n",
    "            pred, attention_weights = model(src, decoder_input, src_pe, tgt_pe)\n",
    "            \n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            pred = pred[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "            tgt_y = tgt_y[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "        \n",
    "            loss = loss_function(pred, tgt_y)\n",
    "            \n",
    "            # Save results for plotting\n",
    "            testing_loss.append(loss.item())\n",
    "            epoch_test_loss = np.mean(testing_loss)\n",
    "            df_testing.loc[epoch] = [epoch, epoch_test_loss]\n",
    "    \n",
    "    loss /= num_batches\n",
    "    # print(f\"Avg test loss: {loss:>8f}\")\n",
    "\n",
    "# Define validation step\n",
    "def validation(dataloader, model):\n",
    "    \n",
    "    # Define lists to store the predictions and ground truth\n",
    "    y_hats = []\n",
    "    tgt_ys = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = batch\n",
    "            src, tgt, tgt_y, src_pe, tgt_pe = src.float().to(device), tgt.float().to(device), tgt_y.float().to(device), src_pe.float().to(device), tgt_pe.float().to(device)\n",
    "            \n",
    "            # Process decoder input\n",
    "            decoder_input = torch.zeros_like(tgt[:, -output_sequence_len:, :]).float()\n",
    "            decoder_input = torch.cat([tgt[:, :decoder_sequence_len, :], decoder_input], dim=1).float().to(device)\n",
    "            \n",
    "            # Compute prediction error\n",
    "            pred, attention_weights = model(src, decoder_input, src_pe, tgt_pe)\n",
    "            \n",
    "            f_dim = -1 if features == 'MS' else 0\n",
    "            pred = pred[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "            tgt_y = tgt_y[:, -decoder_sequence_len:, f_dim:].to(device)\n",
    "            \n",
    "            y_hat = pred.detach().cpu().numpy()\n",
    "            tgt_y = tgt_y.detach().cpu().numpy()\n",
    "            \n",
    "            y_hats.append(y_hat)\n",
    "            tgt_ys.append(tgt_y)\n",
    "    \n",
    "    y_hats = np.concatenate(y_hats, axis=0)\n",
    "    tgt_ys = np.concatenate(tgt_ys, axis=0)\n",
    "    print('Validation shape:', y_hats.shape, tgt_ys.shape)\n",
    "    y_hats = y_hats.reshape(-1, y_hats.shape[-2], y_hats.shape[-1])\n",
    "    tgt_ys = tgt_ys.reshape(-1, tgt_ys.shape[-2], tgt_ys.shape[-1])\n",
    "    print('Validation shape:', y_hats.shape, tgt_ys.shape)\n",
    "    \n",
    "    # Get metrics\n",
    "    mae, mse, rmse, mape, mspe = utils.metric(y_hats, tgt_ys)\n",
    "    print('MSE: {}\\nMAE: {}'.format(mse, mae))\n",
    "    \n",
    "    return y_hats.squeeze(), tgt_ys.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Define seed\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    # Hyperparams\n",
    "    test_size = 0.2\n",
    "    val_size = 0.1\n",
    "    batch_size = 128\n",
    "    src_variables = ['X']\n",
    "    tgt_variables = ['y']\n",
    "    input_variables = src_variables + tgt_variables\n",
    "    timestamp_col_name = \"time\"\n",
    "    model_selection = 'autoformer' # 'autoformer', 'informer', 'fedformer'\n",
    "    \n",
    "    encoder_sequence_len = 365 # length of input given to encoder\n",
    "    decoder_sequence_len = 1 # length of input given to decoder\n",
    "    output_sequence_len = 2 # target sequence length (the informer does not work with 1 step ahead)\n",
    "    encoder_input_size = 1\n",
    "    decoder_input_size = 1\n",
    "    decoder_output_size = 1 \n",
    "    encoder_features_fc_layer = 64\n",
    "    decoder_features_fc_layer = 64\n",
    "    n_encoder_layers = 2\n",
    "    n_decoder_layers = 2\n",
    "    activation = 'gelu'\n",
    "    embed = 'time_frequency'\n",
    "    d_model = 256\n",
    "    n_heads = 4\n",
    "    attention_factor = 1\n",
    "    frequency = 'd'\n",
    "    dropout = 0.05\n",
    "    distill = True # For the Informer: whether to use distilling in encoder, using this argument means not using distilling\n",
    "    output_attention = True # Keep True for now\n",
    "    moving_average = 25\n",
    "    window_size = encoder_sequence_len + output_sequence_len\n",
    "    step_size = 1\n",
    "\n",
    "    # FEDformer specific hyperparams\n",
    "    L = 1\n",
    "    ab = 0\n",
    "    modes = 32\n",
    "    mode_select = 'random'\n",
    "    version = 'Wavelets' # 'Wavelets' or 'Fourier'\n",
    "    base = 'legendre'\n",
    "    cross_activation = 'tanh'\n",
    "    wavelet = 0\n",
    "    \n",
    "    num_workers = 8\n",
    "    features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Get device\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f'Using {device} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Read the data\n",
    "    data = utils.read_data(timestamp_col_name=timestamp_col_name)\n",
    "    data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "    \n",
    "    # Extract train, test, and validation temporal data for position encoding\n",
    "    training_data_pe = data[:-(round(len(data)*(test_size+val_size)))].iloc[:, :1]\n",
    "    testing_data_pe = data.iloc[:, :1][(round(len(data)*(1-test_size-val_size))):(round(len(data)*(1-val_size)))]\n",
    "    validation_data_pe = data.iloc[:, :1][(round(len(data)*(1-val_size))):]\n",
    "    \n",
    "    # Adapt to prediction task\n",
    "    if features == 'M' or features == 'MS':\n",
    "        cols_data = data.columns[1:]\n",
    "        data = data[cols_data]\n",
    "    elif features == 'S':\n",
    "        data = data[[tgt_variables[0]]]\n",
    "    \n",
    "    # Extract train, test and validaiton data\n",
    "    training_data = data[:-(round(len(data)*(test_size+val_size)))]\n",
    "    testing_data = data[(round(len(data)*(1-test_size-val_size))):(round(len(data)*(1-val_size)))]\n",
    "    validation_data = data[(round(len(data)*(1-val_size))):]\n",
    "    \n",
    "    # Make list of (start_idx, end_idx) pairs that are used to slice the time series sequence into chuncks\n",
    "    training_indices = utils.get_indices(data=training_data, window_size=window_size, step_size=step_size)\n",
    "    testing_indices = utils.get_indices(data=testing_data, window_size=window_size, step_size=step_size)\n",
    "    validation_indices = utils.get_indices(data=validation_data, window_size=window_size, step_size=step_size)\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Fit scaler on the training set\n",
    "    scaler.fit(training_data.values)\n",
    "    \n",
    "    training_data = scaler.transform(training_data.values)\n",
    "    testing_data = scaler.transform(testing_data.values)\n",
    "    validation_data = scaler.transform(validation_data.values)\n",
    "\n",
    "    # Extract positional encoding data\n",
    "    training_data_pe = utils.positional_encoder(training_data_pe, time_encoding='time_frequency', frequency='d')\n",
    "    testing_data_pe = utils.positional_encoder(testing_data_pe, time_encoding='time_frequency', frequency='d')\n",
    "    validation_data_pe = utils.positional_encoder(validation_data_pe, time_encoding='time_frequency', frequency='d')\n",
    "    \n",
    "    # Make instance of the custom dataset class\n",
    "    training_data = ds.AutoTransformerDataset(data=torch.tensor(training_data), data_pe=torch.tensor(training_data_pe),\n",
    "                                            indices=training_indices, encoder_sequence_len=encoder_sequence_len, \n",
    "                                            decoder_sequence_len=decoder_sequence_len, tgt_sequence_len=output_sequence_len)\n",
    "    testing_data = ds.AutoTransformerDataset(data=torch.tensor(testing_data), data_pe=torch.tensor(testing_data_pe),\n",
    "                                            indices=testing_indices, encoder_sequence_len=encoder_sequence_len,\n",
    "                                            decoder_sequence_len=decoder_sequence_len, tgt_sequence_len=output_sequence_len)\n",
    "    validation_data = ds.AutoTransformerDataset(data=torch.tensor(validation_data), data_pe=torch.tensor(validation_data_pe),\n",
    "                                            indices=validation_indices, encoder_sequence_len=encoder_sequence_len,\n",
    "                                            decoder_sequence_len=decoder_sequence_len, tgt_sequence_len=output_sequence_len)\n",
    "\n",
    "    # Set up the dataloaders\n",
    "    training_data = DataLoader(training_data, batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "    testing_data = DataLoader(testing_data, batch_size, shuffle=False, num_workers=num_workers, drop_last=False)\n",
    "    validation_data = DataLoader(validation_data, batch_size=1, shuffle=False, num_workers=num_workers, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Build model\n",
    "    if model_selection == 'autoformer':\n",
    "        model = Autoformer(encoder_sequence_len=encoder_sequence_len, decoder_sequence_len=decoder_sequence_len, output_sequence_len=output_sequence_len,\n",
    "                    encoder_input_size=encoder_input_size, decoder_input_size=decoder_input_size, decoder_output_size=decoder_output_size, \n",
    "                    encoder_features_fc_layer=encoder_features_fc_layer, decoder_features_fc_layer=decoder_features_fc_layer, n_encoder_layers=n_encoder_layers,\n",
    "                    n_decoder_layers=n_decoder_layers, activation=activation, embed=embed, d_model=d_model, n_heads=n_heads, attention_factor=attention_factor,\n",
    "                    frequency=frequency, dropout=dropout, output_attention=output_attention, moving_average=moving_average).float()\n",
    "    elif model_selection == 'informer':\n",
    "        model = Informer(output_sequence_len=output_sequence_len, encoder_input_size=encoder_input_size, decoder_input_size=decoder_input_size, \n",
    "                        decoder_output_size=decoder_output_size, encoder_features_fc_layer=encoder_features_fc_layer, decoder_features_fc_layer=decoder_features_fc_layer, \n",
    "                        n_encoder_layers=n_encoder_layers, n_decoder_layers=n_decoder_layers, activation=activation, embed=embed, d_model=d_model, n_heads=n_heads, \n",
    "                        attention_factor=attention_factor, frequency=frequency, dropout=dropout, distill=distill, output_attention=output_attention).float()\n",
    "    elif model_selection == 'fedformer':\n",
    "        model = FEDformer(encoder_sequence_len=encoder_sequence_len, decoder_sequence_len=decoder_sequence_len, output_sequence_len=output_sequence_len,\n",
    "                        encoder_input_size=encoder_input_size, decoder_input_size=decoder_input_size , decoder_output_size=decoder_output_size, \n",
    "                        encoder_features_fc_layer=encoder_features_fc_layer, decoder_features_fc_layer=decoder_features_fc_layer, n_encoder_layers=n_encoder_layers, \n",
    "                        n_decoder_layers=n_decoder_layers, activation=activation, embed=embed, d_model=d_model, n_heads=n_heads, frequency=frequency, \n",
    "                        dropout=dropout, output_attention=output_attention, moving_average=moving_average, version=version, mode_select=model_selection, \n",
    "                        modes=modes, L=L, base=base, cross_activation=cross_activation, wavelet=wavelet).float()\n",
    "    else:\n",
    "        raise ValueError('Model not implemented')\n",
    "\n",
    "    # Send model to device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Print model and number of parameters\n",
    "    print('Defined model:\\n', model)\n",
    "    utils.count_parameters(model)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Update model in the training process and test it\n",
    "    epochs = 400\n",
    "    start_time = time.time()\n",
    "    df_training = pd.DataFrame(columns=('epoch', 'loss_train'))\n",
    "    df_testing = pd.DataFrame(columns=('epoch', 'loss_test'))\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        train(training_data, model, loss_function, optimizer, device, df_training, epoch=t)\n",
    "        test(testing_data, model, loss_function, device, df_testing, epoch=t)\n",
    "    print(\"Done! ---Execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Inference\n",
    "    y_hats, tgt_ys = validation(validation_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # Plot loss\n",
    "    plt.figure(1);plt.clf()\n",
    "    plt.plot(df_training['epoch'], df_training['loss_train'], '-o', label='loss train')\n",
    "    plt.plot(df_training['epoch'], df_testing['loss_test'], '-o', label='loss test')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel(r'epoch')\n",
    "    plt.ylabel(r'loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot validation\n",
    "    plt.figure(2);plt.clf()\n",
    "    plt.plot(tgt_ys, label='observed')\n",
    "    plt.plot(range(len(y_hats)), y_hats, label='predicted')\n",
    "    plt.xlabel(r'time (days)')\n",
    "    plt.ylabel(r'y')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NSE metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    nse = utils.nash_sutcliffe_efficiency(tgt_ys, y_hats)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
